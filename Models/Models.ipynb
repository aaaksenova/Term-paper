{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Препроцессинг и тестирование моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом ноутбуке представлен препроцессинг тестового подкорпуса и обучающей выборки из 1000 примерво, а также сравнивается работа различных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "import logging\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import pymystem3\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка выборки 1000 употреблений *то есть* в НКРЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Работа с таблицей по векам\n",
    "\n",
    "wb = openpyxl.load_workbook('/Users/annaaksenova/Desktop/Работа к Кувшинской/То есть выборка по векам.xlsx')\n",
    "sheet = wb['21'] # Имя листа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Я засунула пластинку и блюдо в один пакет, положила под сиденье и ― надо знать наши самолёты советских времён, лишённые кондиционеров, ― в конце пути в Ереван достала из-под сиденья пластинку, принявшую форму таза, тоесть блюда.', 'Само название места происходит от того, что здесь врачевали «косимых» ― тоесть увечных.', 'Я даже не могу найти концов, тоесть понять, кто же мне, собственно, должен платить.', 'Никаких провокаций ― известные имена-брэнды.  Расчёт на то, что, даже если зритель не шибко приобщён к балету и не знает, кто такая Аньес Летестю, он непременно отреагирует на Opera National de Paris.  Или хотя бы на «Лебединое озеро». Или хотя бы на Paris.  Плюс гарантия качества: звёзды подобраны заслуженные, но при этом, что важно, действующие: спешно доставленные на пароходе прямо из Парижа, поднимешь крышку ― пар!тоесть готовые доказывать свой статус каждым спектаклем.', '«Чтобы не быть выдавленными с рынка, ― говорит академик Алексей Макаров, ― необходимы жесткий расчет экономической эффективности нефтегазовых проектов, контроль затрат по всей цепочке поставок углеводородов, а также правильная оценка возможных рисков, тоесть нужна такая организация бизнес-процессов в отрасли, чтобы перекрывать дорогу чрезмерным затратам».', 'Чёткое определение рынков, ориентация на нужды потребителей, координация всех видов маркетинговой деятельности, направленной на удовлетворение потребителей, позволяют компании получать прибыль из создания потребительской ценности и долговременных отношений.тоесть компания отнюдь не должна пытаться дать потребителям абсолютно всё, что они хотят.', 'Вика отмерла и начала сбивчиво объяснять про какую-то эсэмэску, которую ей прислала какая-то Лилька и которую, в смысле эсэмэску, необходимо было зачем-то показать директрисе, она и показала, а Лидушка почему-то сразу ей мобильник назад не вернула, а сказала, что вернет его завтра, а назавтра ― это четверг, тоесть позавчера ― Лидушка поперлась с полдня на какое-то совещание, а в пятницу, тоесть вчера, Вика промобильник не вспомнила, а потом Лидушку убили.', 'Общероссийским классификатором продукции ОК 005-93, утверждённым постановлением Госстандарта России от 30. 12. 1993№ 301 (далее― Классификатор), продукция рыбная, вылов рыбы и других водных биоресурсов (код 989934) отнесены к продукции животноводства, тоесть к сельскохозяйственной продукции.', 'Чтобы через много лет люди смотрели на них и вспоминали своих бабушек-дедушек, тоесть нас всех.', 'Эти липосомы содержат лиганды к клеточным рецепторам B-клеток (латинская B, «бэ-клетки», они же белые клетки крови ― прим. пресс-службы), тоесть такие молекулы, которые могут взаимодействовать только с определёнными клетками, B-лимфоцитами.']\n"
     ]
    }
   ],
   "source": [
    "v1 = []\n",
    "# Собираем примеры из таблицы\n",
    "for v in sheet.iter_rows(min_row=2, min_col=21, max_col=21, max_row=1001, values_only=True):\n",
    "    if v[0] == None:\n",
    "        v1.append('')\n",
    "    else:\n",
    "        v1.append(v[0].replace(u'\\xa0', ' ').strip())\n",
    "v2 = []\n",
    "for v in sheet.iter_rows(min_row=2, min_col=22, max_col=22, max_row=1001, values_only=True):\n",
    "    if v[0] == None:\n",
    "        v2.append('')\n",
    "    else:\n",
    "        item = v[0].replace(u'\\xa0', ' ')\n",
    "        item = item.strip()\n",
    "        item = item.replace('  ', '')\n",
    "        item = re.sub('\\[.+\\]', '', item)\n",
    "        item = re.sub(r'\\b[Тт]о есть', r'тоесть', item) # \\b убирает случаи что есть\n",
    "        item = re.sub(r'\\b[Аа] именно', r'аименно', item)\n",
    "        item = re.sub(r'\\b[Тт]ак как', r'таккак', item)\n",
    "        item = re.sub(r'\\b[Пп]отому что', r'потомучто', item)\n",
    "        v2.append(item)\n",
    "values = [v1[i]+v2[i] for i in range(1000)]\n",
    "print(values[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Парсим предложения\n",
    "def parser(string):\n",
    "    punctuation = (list(\"\"\",;:”$%^&*№()_—=+|[]{}\\\"/<>`~±§«»°1234567890\"\"\")\n",
    "               + ['- ', ' -', ' - ', '― ', ' ―', ' ― ', \" '\", \"' \"])\n",
    "    string = string.lower()\n",
    "    for ch in list('.…!?'): # Разбиваем примеры на предложения\n",
    "        string = string.replace(ch, '\\n')\n",
    "    for char in punctuation:\n",
    "        string = string.replace(char, ' ')\n",
    "    lemmas = m.lemmatize(string)\n",
    "    parsed = ''.join(lemmas)\n",
    "    parsed = parsed.replace('тоедать', 'тоесть')\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [parser(example) for example in values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Записываем в файл лемматизированные предложения\n",
    "with open('21_century.txt', 'w', encoding='utf-8') as fw:\n",
    "    for i in data:\n",
    "        fw.write(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Препроцессинг корпуса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нужно:\n",
    "1. Соединить слова *то есть, а именно, потому что, так как*\n",
    "2. Убрать омонимию *если, то; не, а*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Volumes/Анна/Corpora/stable/disamb/corpora/lines_1m_to_3m.pickle', 'rb') as f:\n",
    "    data_13 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Volumes/Анна/Corpora/stable/disamb/corpora/lines_3000000.pickle', 'rb') as f:\n",
    "    data_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BigData = data_13 + data_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обрабатываем корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Видим точку не в т.к., т.д. или т.е. - новое предложение\n",
    "text = []  # Список предложений\n",
    "sentence = []  # Обновляемый список слов в предложении\n",
    "k = -1  # Счетчик позиции. Вот если у нас \"т\" из т.е., мы можем не обрабатывать следующие 3 символа\n",
    "for i in range(len(BigData)-2):\n",
    "    if i <= k:  # Если счетчик больше, то мы уже учли это слово\n",
    "        continue\n",
    "    elif len(BigData[i]) != 7:\n",
    "        continue\n",
    "    else:\n",
    "        k = -1\n",
    "        if not (BigData[i][0] == '!' or BigData[i][0] == '?' or BigData[i][0] == '.' or BigData[i][0] == '…') :\n",
    "            if ((BigData[i][0] == 'то' or BigData[i][0] == 'То') \n",
    "                and BigData[i][6] == 'предик' and BigData[i+1][0] == 'есть'):\n",
    "                sentence.append('тоесть')\n",
    "                k = i + 1  # Не смотрим на следующее \"есть\"\n",
    "            elif (BigData[i][0] == 'так' or BigData[i][0] == 'Так') and BigData[i+1][0] == 'как':\n",
    "                sentence.append('таккак')\n",
    "                k = i + 1\n",
    "            elif (BigData[i][0] == 'потому' or BigData[i][0] == 'Потому') and BigData[i+1][0] == 'что':\n",
    "                sentence.append('потомучто')\n",
    "                k = i + 1\n",
    "            elif (BigData[i][0] == 'в' or BigData[i][0] == 'В') and BigData[i+1][0] == 'смысле':\n",
    "                sentence.append('всмысле')  # их всего 156\n",
    "                k = i + 1\n",
    "            elif (BigData[i][0] == 'А' or BigData[i][0] == 'А') and BigData[i+1][0] == 'именно':\n",
    "                sentence.append('аименно')\n",
    "                k = i + 1\n",
    "            elif ((BigData[i][0] == 'т' or BigData[i][0] == 'Т') \n",
    "                  and BigData[i+1][0] == '.' and BigData[i+2][0] == 'е'):\n",
    "                sentence.append('тоесть')\n",
    "                k = i + 3 \n",
    "            elif (BigData[i][0] == 'т' or BigData[i][0] == 'Т') and BigData[i+1][0] == '.' and BigData[i+2][0] == 'к':\n",
    "                sentence.append('таккак')\n",
    "                k = i + 3\n",
    "            elif BigData[i][6] == 'PUNC':  # Если не !.?... но знак препинания, не добавляем\n",
    "                continue\n",
    "            elif (BigData[i][0] == '(' or BigData[i][0] == ')'):\n",
    "                continue\n",
    "            else:\n",
    "                sentence.append(BigData[i][2])\n",
    "        elif not (BigData[i+1][0] == 'п' or BigData[i+1][0] == 'д'):  # Если у нас точка, и она не входит в \"т.п.\" и \"т.д.\"\n",
    "            text.append(sentence)\n",
    "            sentence = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326833"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lems.txt', 'w') as fw:\n",
    "    for i in text:\n",
    "        fw.write(' '.join(i).lower())\n",
    "        fw.write('/n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec CBOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдем к рассмотрению моделей. Загрузим файл со всеми примерами употребления *то есть*, что у нас есть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Volumes/Анна/corp_table.txt\", \"w\") as fw:\n",
    "    for i in text:\n",
    "        fw.write(' '.join(i).lower())\n",
    "        fw.write('/n')\n",
    "    for i in data:\n",
    "        fw.write(' '.join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '/Volumes/Анна/corp_table.txt'\n",
    "data = gensim.models.word2vec.LineSentence(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbow_full = gensim.models.Word2Vec(data, size=300, window=5, min_count=5, iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "model_cbow_full.init_sims(replace=True)\n",
    "model_path = \"to_cbow.bin\"\n",
    "\n",
    "print(\"Saving model...\")\n",
    "model_cbow_full.wv.save_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('но', 0.23746706545352936),\n",
      " ('таккак', 0.2237522304058075),\n",
      " ('и', 0.22348180413246155),\n",
      " ('вот', 0.22122493386268616),\n",
      " ('же', 0.217709481716156),\n",
      " ('для', 0.216770738363266),\n",
      " ('весь', 0.21245142817497253),\n",
      " ('действие', 0.2099384367465973),\n",
      " ('а', 0.20862986147403717),\n",
      " ('быть', 0.20564895868301392)]\n"
     ]
    }
   ],
   "source": [
    "# модель относительно хорошо справилась с выделением ближайших соседей\n",
    "pprint(model_cbow_full.wv.most_similar(\"тоесть\", topn=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Skip-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель на тех же данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gensim.models.word2vec.LineSentence(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to = gensim.models.Word2Vec(data, size=300, window=5, min_count=5, iter=50, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "model_to.init_sims(replace=True)\n",
    "model_path = \"to_sg.bin\"  # сохраняем модель\n",
    "\n",
    "print(\"Saving model...\")\n",
    "model_to.wv.save_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ароматно', 0.3942897915840149),\n",
      " ('оранжевый/nи', 0.34115463495254517),\n",
      " ('охранение', 0.3324703574180603),\n",
      " ('цивилизованно', 0.31085678935050964),\n",
      " ('передел', 0.303924024105072),\n",
      " ('выключатель', 0.30314773321151733),\n",
      " ('переложение', 0.29808560013771057),\n",
      " ('+5', 0.2975841462612152),\n",
      " ('конечно/nлихачева', 0.2955629825592041),\n",
      " ('600.', 0.29418084025382996)]\n"
     ]
    }
   ],
   "source": [
    "# как мы видим, ближайшие соседи не очень осознанные\n",
    "pprint(model_to.wv.most_similar(\"тоесть\", topn=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдем к модели на основе матриц совместной встречаемости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f) as fh:\n",
    "    lines = fh.readlines()\n",
    "lines = [line.split() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 30 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n"
     ]
    }
   ],
   "source": [
    "from glove import Corpus, Glove\n",
    "\n",
    "corpus = Corpus() \n",
    "\n",
    "corpus.fit(lines, window=10)  # Окно 10\n",
    "# Стандартные гиперпараметры для градиентного спуска\n",
    "glove = Glove(no_components=5, learning_rate=0.05)\n",
    " \n",
    "glove.fit(corpus.matrix, epochs=30, no_threads=4, verbose=True)\n",
    "glove.add_dictionary(corpus.dictionary)\n",
    "glove.save('glove.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('–', 0.999085089934544),\n",
      " ('проблема', 0.9988588287344782),\n",
      " ('возникать', 0.9983956958236553),\n",
      " ('честно/n/nи', 0.9977361896826833),\n",
      " ('звучать', 0.9971758819368663),\n",
      " ('иной', 0.9961107612820005),\n",
      " ('отношение', 0.9959756587319284),\n",
      " ('программист', 0.9959280364322133),\n",
      " ('судить', 0.9958511685208293)]\n"
     ]
    }
   ],
   "source": [
    "# Модель не нашла осознанных ближайших соседей\n",
    "pprint(glove.most_similar('тоесть', 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaGram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим модель, выделяющую нескольк значений одного слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 2020-05-27 08:34:24,704 Building dictionary...\n",
      "[INFO] 2020-05-27 08:39:24,047 Done! 21007 words.\n",
      "[INFO] 2020-05-27 08:44:32,820 1.89% -4.9977 0.0245 1.1/2.0 0.21 kwords/sec\n",
      "[INFO] 2020-05-27 08:44:35,156 3.79% -3.9994 0.0241 1.0/2.0 27.39 kwords/sec\n",
      "[INFO] 2020-05-27 08:44:37,600 5.68% -3.6704 0.0236 1.0/2.0 26.19 kwords/sec\n",
      "[INFO] 2020-05-27 08:44:40,029 7.58% -3.5075 0.0231 1.0/2.0 26.35 kwords/sec\n",
      "[INFO] 2020-05-27 08:44:42,434 9.47% -3.4105 0.0226 1.0/2.0 26.62 kwords/sec\n",
      "[INFO] 2020-05-27 08:44:44,910 11.37% -3.3464 0.0222 1.0/2.0 25.84 kwords/sec\n",
      "[INFO] 2020-05-27 08:44:47,263 13.26% -3.3009 0.0217 1.0/2.0 27.20 kwords/sec\n",
      "[INFO] 2020-05-27 08:44:49,665 15.16% -3.2670 0.0212 1.0/2.0 26.64 kwords/sec\n",
      "[INFO] 2020-05-27 08:44:52,029 17.05% -3.2408 0.0207 1.0/2.0 27.07 kwords/sec\n",
      "[INFO] 2020-05-27 08:44:54,346 18.95% -3.2200 0.0203 1.0/2.0 27.62 kwords/sec\n",
      "[INFO] 2020-05-27 08:44:56,761 20.84% -3.2031 0.0198 1.0/2.0 26.50 kwords/sec\n",
      "[INFO] 2020-05-27 08:44:59,064 22.74% -3.1891 0.0193 1.0/2.0 27.80 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:01,463 24.63% -3.1773 0.0188 1.0/2.0 26.68 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:03,812 26.53% -3.1672 0.0184 1.0/2.0 27.25 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:06,132 28.42% -3.1586 0.0179 1.0/2.0 27.59 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:08,498 30.32% -3.1511 0.0174 1.0/2.0 27.05 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:10,920 32.21% -3.1445 0.0169 1.0/2.0 26.42 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:13,479 34.11% -3.1386 0.0165 1.0/2.0 25.01 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:15,989 36.00% -3.1335 0.0160 1.0/2.0 25.50 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:18,437 37.90% -3.1288 0.0155 1.0/2.0 26.14 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:21,176 39.79% -3.1247 0.0151 1.0/2.0 23.36 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:23,586 41.69% -3.1209 0.0146 1.0/2.0 26.56 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:25,980 43.58% -3.1175 0.0141 1.0/2.0 26.74 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:28,433 45.48% -3.1144 0.0136 1.0/2.0 26.09 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:30,786 47.37% -3.1116 0.0132 1.0/2.0 27.20 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:33,193 49.27% -3.1090 0.0127 1.0/2.0 26.60 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:35,526 51.16% -3.1066 0.0122 1.0/2.0 27.43 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:37,904 53.06% -3.1044 0.0117 1.0/2.0 26.91 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:40,288 54.95% -3.1024 0.0113 1.0/2.0 26.84 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:42,691 56.85% -3.1006 0.0108 1.0/2.0 26.63 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:45,100 58.74% -3.0988 0.0103 1.0/2.0 26.57 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:47,436 60.64% -3.0972 0.0098 1.0/2.0 27.39 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:49,796 62.53% -3.0957 0.0094 1.0/2.0 27.12 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:52,147 64.43% -3.0944 0.0089 1.0/2.0 27.22 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:54,491 66.32% -3.0931 0.0084 1.0/2.0 27.31 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:56,797 68.22% -3.0919 0.0079 1.0/2.0 27.75 kwords/sec\n",
      "[INFO] 2020-05-27 08:45:59,158 70.11% -3.0908 0.0075 1.0/2.0 27.10 kwords/sec\n",
      "[INFO] 2020-05-27 08:46:01,517 72.01% -3.0897 0.0070 1.0/2.0 27.14 kwords/sec\n",
      "[INFO] 2020-05-27 08:46:04,073 73.90% -3.0887 0.0065 1.0/2.0 25.04 kwords/sec\n",
      "[INFO] 2020-05-27 08:46:06,489 75.80% -3.0878 0.0061 1.0/2.0 26.49 kwords/sec\n",
      "[INFO] 2020-05-27 08:46:08,989 77.69% -3.0870 0.0056 1.0/2.0 25.60 kwords/sec\n",
      "[INFO] 2020-05-27 08:46:11,476 79.59% -3.0862 0.0051 1.0/2.0 25.73 kwords/sec\n",
      "[INFO] 2020-05-27 08:46:13,912 81.48% -3.0855 0.0046 1.0/2.0 26.27 kwords/sec\n",
      "[INFO] 2020-05-27 08:46:16,396 83.38% -3.0848 0.0042 1.0/2.0 25.77 kwords/sec\n",
      "[INFO] 2020-05-27 08:46:18,910 85.27% -3.0841 0.0037 1.0/2.0 25.46 kwords/sec\n",
      "[INFO] 2020-05-27 08:46:21,360 87.17% -3.0835 0.0032 1.0/2.0 26.13 kwords/sec\n",
      "[INFO] 2020-05-27 08:46:23,756 89.06% -3.0830 0.0027 1.0/2.0 26.71 kwords/sec\n",
      "[INFO] 2020-05-27 08:46:26,114 90.96% -3.0824 0.0023 1.0/2.0 27.15 kwords/sec\n",
      "[INFO] 2020-05-27 08:46:28,438 92.85% -3.0820 0.0018 1.0/2.0 27.53 kwords/sec\n",
      "[INFO] 2020-05-27 08:46:30,825 94.75% -3.0815 0.0013 1.0/2.0 26.82 kwords/sec\n",
      "[INFO] 2020-05-27 08:46:33,354 96.64% -3.0811 0.0008 1.0/2.0 25.30 kwords/sec\n",
      "[INFO] 2020-05-27 08:46:35,752 98.54% -3.0808 0.0004 1.0/2.0 26.69 kwords/sec\n",
      "[INFO] 2020-05-27 08:46:37,632 100.00% -3.0805 0.0000 1.0/2.0 26.26 kwords/sec\n"
     ]
    }
   ],
   "source": [
    "! adagram-train /Volumes/Анна/corp_table.txt out1.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adagram\n",
    "vm = adagram.VectorModel.load('out1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.9998891475446181)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm.word_sense_probs('тоесть')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('дорога/nа', 0, 0.3847712),\n",
       " ('отделать', 0, 0.37543383),\n",
       " ('депрессия', 0, 0.370262),\n",
       " ('вернуться/nно', 0, 0.36666045),\n",
       " ('лавра', 0, 0.33810607),\n",
       " ('высококлассный', 0, 0.33423528),\n",
       " ('ядро', 0, 0.32427284),\n",
       " ('наговорить', 0, 0.31927833),\n",
       " ('как-будто', 0, 0.3191208),\n",
       " ('зарекаться', 0, 0.31838065)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# В этом значении соседи не отражают реальность\n",
    "vm.sense_neighbors('тоесть', 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('принцип', 0, 0.98693883),\n",
       " ('работать', 0, 0.98508406),\n",
       " ('сс', 0, 0.98505765),\n",
       " ('где', 0, 0.9844817),\n",
       " ('основа', 0, 0.98444),\n",
       " ('точка', 0, 0.98418367),\n",
       " ('каждый', 0, 0.98337305),\n",
       " ('всякий', 0, 0.9824113),\n",
       " ('наверное', 0, 0.98168135),\n",
       " ('жить', 0, 0.9815976)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# В этом значении есть слова где, всякий, кажый, наверное, сопоставимые с то есть\n",
    "vm.sense_neighbors('тоесть', 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим визуализацию отношений соседей *то есть*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizations written to ./\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['тоесть']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vec2graph import visualize\n",
    "visualize('./', model_cbow_full.wv, 'тоесть', depth=0, topn=10, threshold=0.3, edge=1, sep=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
