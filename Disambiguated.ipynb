{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import re\n",
    "import pymystem3\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pymystem3 import Mystem\n",
    "import gensim\n",
    "import logging\n",
    "import nltk.data\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import word2vec\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Парсер корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Volumes/Анна/Corpora/stable/disamb/corpora/lines_1m_to_3m.pickle', 'rb') as f:\n",
    "    data_13 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Volumes/Анна/Corpora/stable/disamb/corpora/lines_3000000.pickle', 'rb') as f:\n",
    "    data_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BigData = data_13 + data_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Видим точку не в т.к., т.д. или т.е. - новое предложение\n",
    "text = []  # Список предложений\n",
    "sentence = []  # Обновляемый список слов в предложении\n",
    "k = -1  # Счетчик позиции. Вот если у нас \"т\" из т.е., мы можем не обрабатывать следующие 3 символа\n",
    "for i in range(len(BigData)-2):\n",
    "    if i <= k:  # Если счетчик больше, то мы уже учли это слово\n",
    "        continue\n",
    "    elif len(BigData[i]) != 7:\n",
    "        continue\n",
    "    else:\n",
    "        k = -1\n",
    "        if not (BigData[i][0] == '!' or BigData[i][0] == '?' or BigData[i][0] == '.' or BigData[i][0] == '…') :\n",
    "            if ((BigData[i][0] == 'то' or BigData[i][0] == 'То') \n",
    "                and BigData[i][6] == 'предик' and BigData[i+1][0] == 'есть'):\n",
    "                sentence.append('тоесть')\n",
    "                k = i + 1  # Не смотрим на следующее \"есть\"\n",
    "            elif (BigData[i][0] == 'так' or BigData[i][0] == 'Так') and BigData[i+1][0] == 'как':\n",
    "                sentence.append('таккак')\n",
    "                k = i + 1\n",
    "            elif (BigData[i][0] == 'потому' or BigData[i][0] == 'Потому') and BigData[i+1][0] == 'что':\n",
    "                sentence.append('потомучто')\n",
    "                k = i + 1\n",
    "            elif (BigData[i][0] == 'в' or BigData[i][0] == 'В') and BigData[i+1][0] == 'смысле':\n",
    "                sentence.append('всмысле')  # их всего 156\n",
    "                k = i + 1\n",
    "            elif (BigData[i][0] == 'А' or BigData[i][0] == 'А') and BigData[i+1][0] == 'именно':\n",
    "                sentence.append('аименно')\n",
    "                k = i + 1\n",
    "            elif ((BigData[i][0] == 'т' or BigData[i][0] == 'Т') \n",
    "                  and BigData[i+1][0] == '.' and BigData[i+2][0] == 'е'):\n",
    "                sentence.append('тоесть')\n",
    "                k = i + 3 \n",
    "            elif (BigData[i][0] == 'т' or BigData[i][0] == 'Т') and BigData[i+1][0] == '.' and BigData[i+2][0] == 'к':\n",
    "                sentence.append('таккак')\n",
    "                k = i + 3\n",
    "            elif BigData[i][6] == 'PUNC' or BigData[i][0] == '–':  # Если не !.?... но знак препинания, не добавляем\n",
    "                continue\n",
    "            else:\n",
    "                sentence.append(BigData[i][2])\n",
    "        elif not (BigData[i+1][0] == 'п' or BigData[i+1][0] == 'д'):  # Если у нас точка, и она не входит в \"т.п.\" и \"т.д.\"\n",
    "            text.append(sentence)\n",
    "            sentence = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lems.txt', 'w') as fw:\n",
    "    for i in text:\n",
    "        fw.write(' '.join(i).lower())\n",
    "        fw.write('/n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'lems.txt'\n",
    "data = gensim.models.word2vec.LineSentence(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbow = gensim.models.Word2Vec(data, size=300, window=5, min_count=5, iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "model_cbow.init_sims(replace=True)\n",
    "model_path = \"to.bin\"\n",
    "\n",
    "print(\"Saving model...\")\n",
    "model_cbow.wv.save_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('же', 0.2339174598455429),\n",
      " ('человек', 0.22926689684391022),\n",
      " ('установить', 0.21754902601242065),\n",
      " ('уж', 0.21670973300933838),\n",
      " ('который', 0.21562625467777252),\n",
      " ('порядок', 0.21257881820201874),\n",
      " ('но', 0.20823979377746582),\n",
      " ('политический', 0.20551401376724243),\n",
      " ('вот', 0.2051548957824707),\n",
      " ('а', 0.2025071382522583),\n",
      " ('должно', 0.2024683654308319),\n",
      " ('и', 0.20115657150745392),\n",
      " ('быть', 0.20059838891029358),\n",
      " ('то', 0.20045281946659088),\n",
      " ('далее', 0.19793909788131714),\n",
      " ('что', 0.19752058386802673),\n",
      " ('вещество', 0.19208024442195892),\n",
      " ('в', 0.1920768916606903),\n",
      " ('воздействие', 0.19192764163017273),\n",
      " ('значить', 0.18879765272140503),\n",
      " ('всегда', 0.1868061125278473),\n",
      " ('действие', 0.18424606323242188),\n",
      " ('при', 0.18316248059272766),\n",
      " ('дело', 0.1831446886062622),\n",
      " ('если', 0.1812722533941269),\n",
      " ('счет', 0.18114957213401794),\n",
      " ('путь', 0.1800999939441681),\n",
      " ('таккак', 0.17794837057590485),\n",
      " ('скорее', 0.17755836248397827),\n",
      " ('глубокий', 0.17682623863220215),\n",
      " ('сделать', 0.1757671982049942),\n",
      " ('последовательный', 0.1753937005996704),\n",
      " ('достичь', 0.17481783032417297),\n",
      " ('прием', 0.17454621195793152),\n",
      " ('ум', 0.17448794841766357),\n",
      " ('требовать', 0.17385050654411316),\n",
      " ('мы', 0.17378182709217072),\n",
      " ('вы', 0.17319588363170624),\n",
      " ('именно', 0.17209719121456146),\n",
      " ('гипотетический', 0.17170777916908264),\n",
      " ('дальность', 0.17140766978263855),\n",
      " ('да', 0.17108353972434998),\n",
      " ('ритуал', 0.17106923460960388),\n",
      " ('полный', 0.17104953527450562),\n",
      " ('кто', 0.17086268961429596),\n",
      " ('без', 0.17081990838050842),\n",
      " ('весь', 0.17030194401741028),\n",
      " ('кгб', 0.17001774907112122),\n",
      " ('материальный', 0.16936001181602478),\n",
      " ('современный', 0.16921404004096985)]\n"
     ]
    }
   ],
   "source": [
    "pprint(model_cbow.wv.most_similar(\"тоесть\", topn=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 'я здесь самый умный тоесть как  самый умный  недоумевать'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = l.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('лучший', 3.6221896e-05),\n",
       " ('главное', 3.6005662e-05),\n",
       " ('дело', 3.525131e-05),\n",
       " ('важный', 3.524584e-05),\n",
       " ('умный', 3.4789413e-05),\n",
       " ('красивый', 3.4572855e-05),\n",
       " ('интересный', 3.426596e-05),\n",
       " ('слово', 3.350955e-05),\n",
       " ('смелый', 3.3074713e-05),\n",
       " ('правильный', 3.3052063e-05)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cbow.predict_output_word(l) # Это я не очень поняла как работает, но еще особенно не разбиралась"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дальше я пробовала работать с другими моделями\n",
    "\n",
    "Тут все плоховато"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBOW с моими примерами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"21_century-Copy1.txt\", \"a\") as fw:\n",
    "    for i in text:\n",
    "        fw.write(' '.join(i).lower())\n",
    "        fw.write('/n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '21_century-Copy1.txt'\n",
    "data = gensim.models.word2vec.LineSentence(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbow_full = gensim.models.Word2Vec(data, size=300, window=5, min_count=5, iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "model_cbow_full.init_sims(replace=True)\n",
    "model_path = \"to.bin\"\n",
    "\n",
    "print(\"Saving model...\")\n",
    "model_cbow_full.wv.save_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "MODEL = KeyedVectors.load_word2vec_format('to.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('который', 0.2940874695777893),\n",
      " ('в', 0.2801324725151062),\n",
      " ('и', 0.27532321214675903),\n",
      " ('но', 0.2611147463321686),\n",
      " ('более', 0.250515341758728),\n",
      " ('система', 0.24847330152988434),\n",
      " ('весь', 0.24701091647148132),\n",
      " ('быть', 0.2457403838634491),\n",
      " ('вещество', 0.24558228254318237),\n",
      " ('или', 0.2443869411945343),\n",
      " ('воздействие', 0.24421289563179016),\n",
      " ('то', 0.24326325953006744),\n",
      " ('иметь', 0.24057117104530334),\n",
      " ('обусловить', 0.2402734011411667),\n",
      " ('человек', 0.23677486181259155),\n",
      " ('развитие', 0.23260119557380676),\n",
      " ('их', 0.23105686902999878),\n",
      " ('человеческий', 0.22861215472221375),\n",
      " ('для', 0.22795844078063965),\n",
      " ('же', 0.22307217121124268),\n",
      " ('а', 0.22192877531051636),\n",
      " ('необходимость', 0.22090625762939453),\n",
      " ('получать', 0.22060106694698334),\n",
      " ('значит', 0.21984604001045227),\n",
      " ('поддержание', 0.2176116555929184),\n",
      " ('«', 0.21673578023910522),\n",
      " ('поэтому', 0.2156844139099121),\n",
      " ('как', 0.21504560112953186),\n",
      " ('реформа', 0.2148822844028473),\n",
      " ('на', 0.21421800553798676),\n",
      " ('при', 0.21261638402938843),\n",
      " ('определять', 0.21244531869888306),\n",
      " ('определение', 0.2113962024450302),\n",
      " ('управлять', 0.2112892121076584),\n",
      " ('каждый', 0.21058976650238037),\n",
      " ('таккак', 0.21040070056915283),\n",
      " ('поддерживать', 0.21038857102394104),\n",
      " ('соображение', 0.21003934741020203),\n",
      " ('достигнуть', 0.20758956670761108),\n",
      " ('требовать', 0.2074701488018036),\n",
      " ('либо', 0.20708498358726501),\n",
      " ('они', 0.20566442608833313),\n",
      " ('индекс', 0.20466920733451843),\n",
      " ('мы', 0.20249149203300476),\n",
      " ('определенный', 0.20096421241760254),\n",
      " ('начинать', 0.20052143931388855),\n",
      " ('соответствие', 0.1995433270931244),\n",
      " ('установленный', 0.19954004883766174),\n",
      " ('без', 0.19933797419071198),\n",
      " ('экономический', 0.19922056794166565)]\n"
     ]
    }
   ],
   "source": [
    "pprint(model_cbow_full.wv.most_similar(\"тоесть\", topn=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Skip-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ничего не работает, потому что это skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '21_century-Copy1.txt'\n",
    "data = gensim.models.word2vec.LineSentence(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sg = gensim.models.Word2Vec(data, size=300, window=5, min_count=5, iter=50, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "model_sg.init_sims(replace=True)\n",
    "model_path = \"to.bin\"\n",
    "\n",
    "print(\"Saving model...\")\n",
    "model_sg.wv.save_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('невозможно/nтоесть', 0.33740538358688354),\n",
       " ('прогрессивнее', 0.3313928246498108),\n",
       " ('11-13', 0.3291909694671631),\n",
       " ('уровень/nи', 0.3153378367424011),\n",
       " ('и', 0.3144078254699707),\n",
       " ('спг', 0.31358468532562256),\n",
       " ('уклад', 0.31152862310409546),\n",
       " ('новoгo', 0.31128817796707153),\n",
       " ('прцент/n)', 0.30413293838500977),\n",
       " ('ароматно', 0.3036803901195526),\n",
       " ('общенародный', 0.30315157771110535),\n",
       " ('а', 0.3015827238559723),\n",
       " ('обтекаемый', 0.2996218800544739),\n",
       " ('тыс', 0.2992943227291107),\n",
       " ('воздействие', 0.29762357473373413),\n",
       " ('отчисление', 0.2953924536705017),\n",
       " ('бездействовать', 0.2939915060997009),\n",
       " ('но', 0.29247188568115234),\n",
       " ('сколько-нибудь', 0.2914343476295471),\n",
       " ('bs', 0.2910422682762146),\n",
       " ('вливать', 0.28934359550476074),\n",
       " ('усвоение', 0.28910285234451294),\n",
       " ('изогнутый', 0.2890014946460724),\n",
       " ('читаемость', 0.2876467704772949),\n",
       " ('млн', 0.2873305678367615),\n",
       " ('способность/nв', 0.28715139627456665),\n",
       " ('тор-м1', 0.28462672233581543),\n",
       " ('высвобождаться', 0.2843358814716339),\n",
       " ('интенсификация', 0.2842598259449005),\n",
       " ('визави', 0.2839679718017578),\n",
       " ('перехват', 0.28349924087524414),\n",
       " ('трибунал', 0.2833977937698364),\n",
       " ('запугивание', 0.2831228971481323),\n",
       " ('умолчание', 0.28306883573532104),\n",
       " ('уровня', 0.282228946685791),\n",
       " ('медикомент', 0.28144097328186035),\n",
       " ('ядро', 0.28141114115715027),\n",
       " ('tcp', 0.2813073992729187),\n",
       " ('вещество', 0.28103750944137573),\n",
       " ('интеллект/nв', 0.2805624008178711),\n",
       " ('60-70', 0.28025102615356445),\n",
       " ('традиционный', 0.2798632085323334),\n",
       " ('передел', 0.27979031205177307),\n",
       " ('зенитный', 0.27952319383621216),\n",
       " ('онищенко', 0.27936744689941406),\n",
       " ('пережить/nи', 0.27886641025543213),\n",
       " ('галактический', 0.27857595682144165),\n",
       " ('доллар/nсейчас', 0.27834776043891907),\n",
       " ('максимализм', 0.27824175357818604),\n",
       " ('газ', 0.27760255336761475)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sg.wv.most_similar(\"тоесть\", topn=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут все совсем странно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('21_century-Copy1.txt') as fh:\n",
    "    lines = fh.readlines()\n",
    "lines = [line.split() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 30 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n"
     ]
    }
   ],
   "source": [
    "#importing the glove library\n",
    "from glove import Corpus, Glove\n",
    "# creating a corpus object\n",
    "corpus = Corpus() \n",
    "#training the corpus to generate the co occurence matrix which is used in GloVe\n",
    "corpus.fit(lines, window=10)\n",
    "#creating a Glove object which will use the matrix created in the above lines to create embeddings\n",
    "#We can set the learning rate as it uses Gradient Descent and number of components\n",
    "glove = Glove(no_components=5, learning_rate=0.05)\n",
    " \n",
    "glove.fit(corpus.matrix, epochs=30, no_threads=4, verbose=True)\n",
    "glove.add_dictionary(corpus.dictionary)\n",
    "glove.save('glove.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('дело/nи', 0.9995947446055201), ('появиться', 0.9989923279255014), ('например', 0.9989316235175412), ('весь', 0.9987825329634878)]\n"
     ]
    }
   ],
   "source": [
    "print(glove.most_similar('тоесть'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaGram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во втором значении модель говорит, что *то есть* похоже на какие-то редкие полнозначные слова. В первом значении немного получше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 2020-02-03 09:40:19,500 Building dictionary...\n",
      "[INFO] 2020-02-03 09:45:00,428 Done! 21138 words.\n",
      "[INFO] 2020-02-03 09:49:34,040 1.98% -7.3071 0.0245 1.2/2.0 0.23 kwords/sec\n",
      "[INFO] 2020-02-03 09:49:37,808 3.96% -7.1314 0.0240 1.3/3.0 16.98 kwords/sec\n",
      "[INFO] 2020-02-03 09:49:41,586 5.94% -6.9853 0.0235 1.5/4.0 16.94 kwords/sec\n",
      "[INFO] 2020-02-03 09:49:45,349 7.92% -6.8650 0.0230 1.6/5.0 17.00 kwords/sec\n",
      "[INFO] 2020-02-03 09:49:49,035 9.90% -6.7619 0.0225 1.6/5.0 17.36 kwords/sec\n",
      "[INFO] 2020-02-03 09:49:52,631 11.88% -6.6703 0.0220 1.7/5.0 17.80 kwords/sec\n",
      "[INFO] 2020-02-03 09:49:56,166 13.86% -6.5874 0.0215 1.7/5.0 18.11 kwords/sec\n",
      "[INFO] 2020-02-03 09:49:59,669 15.84% -6.5116 0.0210 1.7/5.0 18.27 kwords/sec\n",
      "[INFO] 2020-02-03 09:50:03,148 17.83% -6.4419 0.0205 1.8/5.0 18.39 kwords/sec\n",
      "[INFO] 2020-02-03 09:50:06,610 19.81% -6.3778 0.0200 1.8/5.0 18.49 kwords/sec\n",
      "[INFO] 2020-02-03 09:50:10,069 21.79% -6.3186 0.0196 1.8/5.0 18.50 kwords/sec\n",
      "[INFO] 2020-02-03 09:50:13,496 23.77% -6.2640 0.0191 1.8/5.0 18.68 kwords/sec\n",
      "[INFO] 2020-02-03 09:50:16,923 25.75% -6.2136 0.0186 1.8/5.0 18.67 kwords/sec\n",
      "[INFO] 2020-02-03 09:50:20,333 27.73% -6.1670 0.0181 1.8/5.0 18.77 kwords/sec\n",
      "[INFO] 2020-02-03 09:50:23,752 29.71% -6.1238 0.0176 1.8/5.0 18.72 kwords/sec\n",
      "[INFO] 2020-02-03 09:50:27,155 31.69% -6.0837 0.0171 1.8/5.0 18.80 kwords/sec\n",
      "[INFO] 2020-02-03 09:50:30,568 33.67% -6.0463 0.0166 1.8/5.0 18.76 kwords/sec\n",
      "[INFO] 2020-02-03 09:50:33,991 35.65% -6.0115 0.0161 1.9/5.0 18.70 kwords/sec\n",
      "[INFO] 2020-02-03 09:50:37,387 37.63% -5.9790 0.0156 1.9/5.0 18.85 kwords/sec\n",
      "[INFO] 2020-02-03 09:50:40,793 39.61% -5.9486 0.0151 1.9/5.0 18.79 kwords/sec\n",
      "[INFO] 2020-02-03 09:50:44,176 41.59% -5.9201 0.0146 1.9/5.0 18.92 kwords/sec\n",
      "[INFO] 2020-02-03 09:50:47,579 43.57% -5.8933 0.0141 1.9/5.0 18.81 kwords/sec\n",
      "[INFO] 2020-02-03 09:50:50,964 45.55% -5.8682 0.0136 1.9/5.0 18.91 kwords/sec\n",
      "[INFO] 2020-02-03 09:50:54,352 47.53% -5.8445 0.0131 1.9/5.0 18.89 kwords/sec\n",
      "[INFO] 2020-02-03 09:50:57,706 49.52% -5.8222 0.0126 1.9/5.0 19.08 kwords/sec\n",
      "[INFO] 2020-02-03 09:51:01,067 51.50% -5.8011 0.0121 1.9/5.0 19.04 kwords/sec\n",
      "[INFO] 2020-02-03 09:51:04,414 53.48% -5.7811 0.0116 1.9/5.0 19.12 kwords/sec\n",
      "[INFO] 2020-02-03 09:51:07,752 55.46% -5.7622 0.0111 1.9/5.0 19.17 kwords/sec\n",
      "[INFO] 2020-02-03 09:51:11,099 57.44% -5.7443 0.0106 1.9/5.0 19.12 kwords/sec\n",
      "[INFO] 2020-02-03 09:51:14,433 59.42% -5.7273 0.0101 1.9/5.0 19.19 kwords/sec\n",
      "[INFO] 2020-02-03 09:51:17,772 61.40% -5.7110 0.0097 1.9/5.0 19.17 kwords/sec\n",
      "[INFO] 2020-02-03 09:51:21,109 63.38% -5.6956 0.0092 1.9/5.0 19.18 kwords/sec\n",
      "[INFO] 2020-02-03 09:51:24,427 65.36% -5.6809 0.0087 1.9/5.0 19.29 kwords/sec\n",
      "[INFO] 2020-02-03 09:51:27,755 67.34% -5.6669 0.0082 1.9/5.0 19.23 kwords/sec\n",
      "[INFO] 2020-02-03 09:51:31,102 69.32% -5.6536 0.0077 1.9/5.0 19.12 kwords/sec\n",
      "[INFO] 2020-02-03 09:51:34,432 71.30% -5.6408 0.0072 1.9/5.0 19.22 kwords/sec\n",
      "[INFO] 2020-02-03 09:51:37,766 73.28% -5.6286 0.0067 2.0/5.0 19.19 kwords/sec\n",
      "[INFO] 2020-02-03 09:51:41,089 75.26% -5.6169 0.0062 2.0/5.0 19.26 kwords/sec\n",
      "[INFO] 2020-02-03 09:51:44,434 77.24% -5.6058 0.0057 2.0/5.0 19.13 kwords/sec\n",
      "[INFO] 2020-02-03 09:51:47,784 79.22% -5.5951 0.0052 2.0/5.0 19.10 kwords/sec\n",
      "[INFO] 2020-02-03 09:51:51,153 81.20% -5.5849 0.0047 2.0/5.0 19.00 kwords/sec\n",
      "[INFO] 2020-02-03 09:51:54,482 83.19% -5.5751 0.0042 2.0/5.0 19.22 kwords/sec\n",
      "[INFO] 2020-02-03 09:51:57,811 85.17% -5.5658 0.0037 2.0/5.0 19.22 kwords/sec\n",
      "[INFO] 2020-02-03 09:52:01,154 87.15% -5.5568 0.0032 2.0/5.0 19.14 kwords/sec\n",
      "[INFO] 2020-02-03 09:52:04,492 89.13% -5.5483 0.0027 2.0/5.0 19.17 kwords/sec\n",
      "[INFO] 2020-02-03 09:52:07,842 91.11% -5.5402 0.0022 2.0/5.0 19.10 kwords/sec\n",
      "[INFO] 2020-02-03 09:52:11,183 93.09% -5.5325 0.0017 2.0/5.0 19.16 kwords/sec\n",
      "[INFO] 2020-02-03 09:52:14,510 95.07% -5.5251 0.0012 2.0/5.0 19.24 kwords/sec\n",
      "[INFO] 2020-02-03 09:52:17,844 97.05% -5.5182 0.0007 2.0/5.0 19.19 kwords/sec\n",
      "[INFO] 2020-02-03 09:52:21,179 99.03% -5.5117 0.0002 2.0/5.0 19.19 kwords/sec\n",
      "[INFO] 2020-02-03 09:52:22,804 100.00% -5.5054 0.0000 2.1/5.0 19.28 kwords/sec\n"
     ]
    }
   ],
   "source": [
    "! adagram-train 21_century-Copy1.txt disamb.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adagram\n",
    "vm = adagram.VectorModel.load('disamb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.9999454178265379)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm.word_sense_probs('тоесть')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('кнут', 0, 0.4049072),\n",
       " ('переулок', 0, 0.35147887),\n",
       " ('старое', 0, 0.341325),\n",
       " ('дегустация', 0, 0.3382282),\n",
       " ('завязываться', 0, 0.3379058),\n",
       " ('конце-концов', 0, 0.33070037),\n",
       " ('темнеть', 0, 0.32989046),\n",
       " ('более-менее', 0, 0.32591155),\n",
       " ('видеть', 0, 0.32531103),\n",
       " ('положить', 0, 0.32296586)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vm.sense_neighbors('тоесть', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Visualizations written to ./\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['тоесть']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vec2graph import visualize\n",
    "visualize('./', MODEL, 'тоесть', depth=0, topn=10, threshold=0.3, edge=1, sep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth=0, topn=8, threshold=0.62, edge=1, sep=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
